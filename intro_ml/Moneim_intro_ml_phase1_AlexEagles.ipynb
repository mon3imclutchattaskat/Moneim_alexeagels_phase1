{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgzqRAZB7MLT"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4anaTMQ48dvz"
      },
      "source": [
        "## Loading el dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAMBYcep7BLJ",
        "outputId": "1a030585-a150-4e0a-89c5-ad833db40d82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   red  green  blue   label\n",
            "0  226    158    50  Orange\n",
            "1   76     21    88  Purple\n",
            "2  146     70   179  Purple\n",
            "3   18    240   118   Green\n",
            "4  146    253   227   Green\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('data.csv')\n",
        "\n",
        "# Display some rows\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2UQaqrF9fU3"
      },
      "source": [
        "## Preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LPvr0Af8jq-",
        "outputId": "d5aaefff-d4bf-4453-a4a6-7b9c88552ed0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed Data:\n",
            "        red     green      blue   label  encoded_label\n",
            "0  0.886275  0.619608  0.196078  Orange              5\n",
            "1  0.298039  0.082353  0.345098  Purple              7\n",
            "2  0.572549  0.274510  0.701961  Purple              7\n",
            "3  0.070588  0.941176  0.462745   Green              3\n",
            "4  0.572549  0.992157  0.890196   Green              3\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "\n",
        "# Normalize RGB values\n",
        "scaler = MinMaxScaler()\n",
        "data[['red', 'green', 'blue']] = scaler.fit_transform(data[['red', 'green', 'blue']])\n",
        "\n",
        "# Encode color labels\n",
        "label_encoder = LabelEncoder()\n",
        "data['encoded_label'] = label_encoder.fit_transform(data['label'])\n",
        "\n",
        "print(f\"Preprocessed Data:\\n{data.head()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGhqsxNv9mZN"
      },
      "source": [
        "## Split the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cwc8ikC9HP8",
        "outputId": "f423c1a6-0adf-410b-c2ac-a2a0fec95f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 3536\n",
            "Validation set size: 758\n",
            "Test set size: 758\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "X = data[['red', 'green', 'blue']].to_numpy()\n",
        "y = data['label'].to_numpy()\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "print(\"Training set size:\", len(X_train))\n",
        "print(\"Validation set size:\", len(X_val))\n",
        "print(\"Test set size:\", len(X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpoxOyR2--sQ"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0Z_igfG_Aq7"
      },
      "source": [
        "## 1 - KNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKoI68Jg_SCh"
      },
      "source": [
        "### model beda2y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "OL5b4Otz9pUY",
        "outputId": "2eae0531-13e6-4c16-b0be-1610e9a48224"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize and train the model\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "knn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGIR2Ikg93ds",
        "outputId": "d9fd8958-98ae-4b66-d96d-ddd877e4725d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.8390501319261213\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "X_combined_train = np.concatenate((X_train, X_val), axis=0)\n",
        "y_combined_train = np.concatenate((y_train, y_val), axis=0)\n",
        "\n",
        "knn.fit(X_combined_train, y_combined_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = knn.predict(X_test)\n",
        "print(f'KNN Accuracy: {accuracy_score(y_test, y_pred)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-IY0Dvn_U9B"
      },
      "source": [
        "### KNN fine-tuning\n",
        "Experiment with different hyperparameters for each model to improve performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7V8n7EK-jw-",
        "outputId": "eabc65e9-a5cc-437f-f40d-b602dc904af2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best KNN Parameters: {'n_neighbors': 9}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {'n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17, 19, 21]}\n",
        "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5)\n",
        "grid_search.fit(X_combined_train, y_combined_train)\n",
        "print(f'Best KNN Parameters: {grid_search.best_params_}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpsDfCfzERX_"
      },
      "source": [
        "### Final KNN model using the best hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiDNIBhC-ph0",
        "outputId": "8905f0a5-76ce-4e13-eb1e-f1c7ea7e0094"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 0.8548812664907651\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Initialize and train the model\n",
        "knn = KNeighborsClassifier(n_neighbors=grid_search.best_params_['n_neighbors'])\n",
        "knn.fit(X_combined_train, y_combined_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = knn.predict(X_test)\n",
        "print(f'KNN Accuracy: {accuracy_score(y_test, y_pred)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro4i3BI7_iF2"
      },
      "source": [
        "### KNN Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bj0yf3HK-02i",
        "outputId": "d1dc472c-eb32-46f2-b1ee-01aa9b9e14d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Black       1.00      0.91      0.95        11\n",
            "        Blue       0.93      0.90      0.91       169\n",
            "       Brown       0.72      0.92      0.81        52\n",
            "       Green       0.91      0.94      0.93       212\n",
            "        Grey       0.78      0.81      0.79        26\n",
            "      Orange       0.82      0.82      0.82        34\n",
            "        Pink       0.82      0.80      0.81        79\n",
            "      Purple       0.79      0.73      0.76        90\n",
            "         Red       0.71      0.77      0.74        35\n",
            "       White       0.75      0.38      0.50         8\n",
            "      Yellow       0.91      0.71      0.80        42\n",
            "\n",
            "    accuracy                           0.85       758\n",
            "   macro avg       0.83      0.79      0.80       758\n",
            "weighted avg       0.86      0.85      0.85       758\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Evaluate KNN\n",
        "print(\"KNN Classification Report:\")\n",
        "print(classification_report(y_test, knn.predict(X_test), target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uBHc98__poX"
      },
      "source": [
        "## 2 - Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAECSZrvCkcn"
      },
      "source": [
        "### model beda2y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edgD7z37_I6B",
        "outputId": "ddfe0ff4-7b74-4027-c192-cff68d260e6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy: 0.8654353562005277\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Black       1.00      0.91      0.95        11\n",
            "        Blue       0.93      0.92      0.93       169\n",
            "       Brown       0.75      0.88      0.81        52\n",
            "       Green       0.89      0.97      0.93       212\n",
            "        Grey       0.79      0.58      0.67        26\n",
            "      Orange       0.77      0.79      0.78        34\n",
            "        Pink       0.80      0.87      0.84        79\n",
            "      Purple       0.87      0.79      0.83        90\n",
            "         Red       0.79      0.66      0.72        35\n",
            "       White       0.75      0.38      0.50         8\n",
            "      Yellow       0.91      0.76      0.83        42\n",
            "\n",
            "    accuracy                           0.87       758\n",
            "   macro avg       0.84      0.77      0.80       758\n",
            "weighted avg       0.87      0.87      0.86       758\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize the Random Forest model with regularization parameters\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=100,          # Number of trees\n",
        "    max_depth=10,              # Maximum depth of the trees\n",
        "    min_samples_split=5,       # Minimum number of samples required to split a node\n",
        "    min_samples_leaf=3,        # Minimum number of samples required at a leaf node\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "rf.fit(X_combined_train, y_combined_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf.predict(X_test)\n",
        "print(f'Random Forest Accuracy: {accuracy_score(y_test, y_pred)}')\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2iwyhX7EBhA"
      },
      "source": [
        "### Random Forest Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WILqxA_dEEzt",
        "outputId": "0efffa72-4119-4f00-f995-60181055ac54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
            "1080 fits failed out of a total of 3240.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "675 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1145, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 638, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "405 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1145, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 638, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.86199306 0.86227715 0.86425535\n",
            " 0.86454103 0.8651048  0.86793406 0.85973477 0.86171337 0.86227875\n",
            " 0.85605647 0.86256123 0.86369357 0.86143009 0.86001726 0.86397726\n",
            " 0.86199706 0.86030055 0.86001806 0.86086552 0.861148   0.86256363\n",
            " 0.86086552 0.861148   0.86256363 0.85690592 0.85803706 0.8591694\n",
            " 0.86199306 0.86227715 0.86425535 0.86454103 0.8651048  0.86793406\n",
            " 0.85973477 0.86171337 0.86227875 0.85605647 0.86256123 0.86369357\n",
            " 0.86143009 0.86001726 0.86397726 0.86199706 0.86030055 0.86001806\n",
            " 0.86086552 0.861148   0.86256363 0.86086552 0.861148   0.86256363\n",
            " 0.85690592 0.85803706 0.8591694         nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.85803666 0.86114601 0.86340909 0.86397646 0.86369317 0.86340989\n",
            " 0.86199466 0.85860163 0.86397526 0.86256083 0.86114561 0.86284412\n",
            " 0.86030174 0.86143209 0.86369397 0.85690632 0.85718801 0.8591686\n",
            " 0.85747249 0.85662503 0.85973637 0.85747249 0.85662503 0.85973637\n",
            " 0.85520901 0.85549189 0.85775538 0.85803666 0.86114601 0.86340909\n",
            " 0.86397646 0.86369317 0.86340989 0.86199466 0.85860163 0.86397526\n",
            " 0.86256083 0.86114561 0.86284412 0.86030174 0.86143209 0.86369397\n",
            " 0.85690632 0.85718801 0.8591686  0.85747249 0.85662503 0.85973637\n",
            " 0.85747249 0.85662503 0.85973637 0.85520901 0.85549189 0.85775538\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.86284172 0.86199426 0.86453823\n",
            " 0.86454103 0.86538769 0.86849943 0.85973477 0.86171337 0.86227875\n",
            " 0.85605607 0.86369118 0.86425854 0.86143009 0.86001726 0.86426014\n",
            " 0.86199706 0.86030055 0.86001806 0.86086552 0.861148   0.86256363\n",
            " 0.86086552 0.861148   0.86256363 0.85690592 0.85775418 0.8591694\n",
            " 0.86284172 0.86199426 0.86453823 0.86454103 0.86538769 0.86849943\n",
            " 0.85973477 0.86171337 0.86227875 0.85605607 0.86369118 0.86425854\n",
            " 0.86143009 0.86001726 0.86426014 0.86199706 0.86030055 0.86001806\n",
            " 0.86086552 0.861148   0.86256363 0.86086552 0.861148   0.86256363\n",
            " 0.85690592 0.85775418 0.8591694         nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.86199306 0.86227715 0.86425535 0.86454103 0.8651048  0.86793406\n",
            " 0.85973477 0.86171337 0.86227875 0.85605647 0.86256123 0.86369357\n",
            " 0.86143009 0.86001726 0.86397726 0.86199706 0.86030055 0.86001806\n",
            " 0.86086552 0.861148   0.86256363 0.86086552 0.861148   0.86256363\n",
            " 0.85690592 0.85803706 0.8591694  0.86199306 0.86227715 0.86425535\n",
            " 0.86454103 0.8651048  0.86793406 0.85973477 0.86171337 0.86227875\n",
            " 0.85605647 0.86256123 0.86369357 0.86143009 0.86001726 0.86397726\n",
            " 0.86199706 0.86030055 0.86001806 0.86086552 0.861148   0.86256363\n",
            " 0.86086552 0.861148   0.86256363 0.85690592 0.85803706 0.8591694\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.85238175 0.85407747 0.85549109\n",
            " 0.85831715 0.86114561 0.86170978 0.86086512 0.86001606 0.86369157\n",
            " 0.86029855 0.86425695 0.86651763 0.86454023 0.86171218 0.86114481\n",
            " 0.86171258 0.86058143 0.86284292 0.86001486 0.86001446 0.86284412\n",
            " 0.86001486 0.86001446 0.86284412 0.86255963 0.86340869 0.86199386\n",
            " 0.85238175 0.85407747 0.85549109 0.85831715 0.86114561 0.86170978\n",
            " 0.86086512 0.86001606 0.86369157 0.86029855 0.86425695 0.86651763\n",
            " 0.86454023 0.86171218 0.86114481 0.86171258 0.86058143 0.86284292\n",
            " 0.86001486 0.86001446 0.86284412 0.86001486 0.86001446 0.86284412\n",
            " 0.86255963 0.86340869 0.86199386        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.85944749 0.86199426 0.86142649 0.86171258 0.85888292 0.86368918\n",
            " 0.86115    0.861148   0.86199586 0.86058103 0.86086272 0.86171098\n",
            " 0.86142889 0.86142689 0.86086232 0.85577718 0.85945149 0.85860243\n",
            " 0.85747249 0.85888612 0.86256163 0.85747249 0.85888612 0.86256163\n",
            " 0.85945029 0.86227875 0.86284532 0.85944749 0.86199426 0.86142649\n",
            " 0.86171258 0.85888292 0.86368918 0.86115    0.861148   0.86199586\n",
            " 0.86058103 0.86086272 0.86171098 0.86142889 0.86142689 0.86086232\n",
            " 0.85577718 0.85945149 0.85860243 0.85747249 0.85888612 0.86256163\n",
            " 0.85747249 0.85888612 0.86256163 0.85945029 0.86227875 0.86284532\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan 0.8515331  0.85266384 0.85407787\n",
            " 0.85860004 0.86199426 0.86142649 0.86086512 0.86058183 0.86369157\n",
            " 0.86143049 0.86453983 0.86623515 0.86369197 0.86086392 0.86199306\n",
            " 0.86171258 0.86086432 0.8631258  0.86001486 0.86001446 0.86284412\n",
            " 0.86001486 0.86001446 0.86284412 0.86255963 0.86340869 0.86227675\n",
            " 0.8515331  0.85266384 0.85407787 0.85860004 0.86199426 0.86142649\n",
            " 0.86086512 0.86058183 0.86369157 0.86143049 0.86453983 0.86623515\n",
            " 0.86369197 0.86086392 0.86199306 0.86171258 0.86086432 0.8631258\n",
            " 0.86001486 0.86001446 0.86284412 0.86001486 0.86001446 0.86284412\n",
            " 0.86255963 0.86340869 0.86227675        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            "        nan        nan        nan        nan        nan        nan\n",
            " 0.85238175 0.85407747 0.85549109 0.85831715 0.86114561 0.86170978\n",
            " 0.86086512 0.86001606 0.86369157 0.86029855 0.86425695 0.86651763\n",
            " 0.86454023 0.86171218 0.86114481 0.86171258 0.86058143 0.86284292\n",
            " 0.86001486 0.86001446 0.86284412 0.86001486 0.86001446 0.86284412\n",
            " 0.86255963 0.86340869 0.86199386 0.85238175 0.85407747 0.85549109\n",
            " 0.85831715 0.86114561 0.86170978 0.86086512 0.86001606 0.86369157\n",
            " 0.86029855 0.86425695 0.86651763 0.86454023 0.86171218 0.86114481\n",
            " 0.86171258 0.86058143 0.86284292 0.86001486 0.86001446 0.86284412\n",
            " 0.86001486 0.86001446 0.86284412 0.86255963 0.86340869 0.86199386]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Validation Accuracy: 0.8482849604221636\n",
            "Random Forest Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Black       0.86      1.00      0.92         6\n",
            "        Blue       0.85      0.94      0.89       153\n",
            "       Brown       0.81      0.82      0.82        68\n",
            "       Green       0.92      0.93      0.92       230\n",
            "        Grey       0.83      0.47      0.60        32\n",
            "      Orange       0.76      0.91      0.83        32\n",
            "        Pink       0.81      0.84      0.82        92\n",
            "      Purple       0.81      0.69      0.74        78\n",
            "         Red       0.85      0.62      0.72        37\n",
            "       White       0.40      1.00      0.57         2\n",
            "      Yellow       0.75      0.86      0.80        28\n",
            "\n",
            "    accuracy                           0.85       758\n",
            "   macro avg       0.79      0.82      0.79       758\n",
            "weighted avg       0.85      0.85      0.84       758\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the parameter grid for Random Forest with regularization\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV for Random Forest\n",
        "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV on the training data\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from GridSearchCV\n",
        "best_rf = grid_search_rf.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the validation set\n",
        "y_val_pred_rf = best_rf.predict(X_val)\n",
        "print(f'Random Forest Validation Accuracy: {accuracy_score(y_val, y_val_pred_rf)}')\n",
        "print(\"Random Forest Validation Classification Report:\")\n",
        "print(classification_report(y_val, y_val_pred_rf, target_names=label_encoder.classes_))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RyJB1SGE-4S"
      },
      "source": [
        "### Final evaluation random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilI3p2OUE-WM",
        "outputId": "513629c8-300c-49a3-9b21-98ec3ae39285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Test Accuracy: 0.8548812664907651\n",
            "Random Forest Test Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Black       1.00      0.91      0.95        11\n",
            "        Blue       0.90      0.92      0.91       169\n",
            "       Brown       0.79      0.87      0.83        52\n",
            "       Green       0.88      0.94      0.91       212\n",
            "        Grey       0.77      0.65      0.71        26\n",
            "      Orange       0.80      0.82      0.81        34\n",
            "        Pink       0.79      0.85      0.82        79\n",
            "      Purple       0.85      0.77      0.81        90\n",
            "         Red       0.73      0.69      0.71        35\n",
            "       White       0.80      0.50      0.62         8\n",
            "      Yellow       0.91      0.71      0.80        42\n",
            "\n",
            "    accuracy                           0.85       758\n",
            "   macro avg       0.84      0.78      0.81       758\n",
            "weighted avg       0.86      0.85      0.85       758\n",
            "\n",
            "Best parameters found:\n",
            "{'bootstrap': True, 'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n"
          ]
        }
      ],
      "source": [
        "# Final evaluation on test data\n",
        "y_test_pred_rf = best_rf.predict(X_test)\n",
        "print(f'Random Forest Test Accuracy: {accuracy_score(y_test, y_test_pred_rf)}')\n",
        "print(\"Random Forest Test Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred_rf, target_names=label_encoder.classes_))\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best parameters found:\")\n",
        "print(grid_search_rf.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqs_5RZ1ErXS"
      },
      "source": [
        "## 3 - Gradient Boosting Model (Boosting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxB--01FHCw7"
      },
      "source": [
        "### model beda2y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trFKqbxnFTbA",
        "outputId": "ee8bf0e3-7fbd-4d55-fc8c-0b91b33719d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Validation Accuracy: 0.8469656992084432\n",
            "Gradient Boosting Validation Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Black       0.86      1.00      0.92         6\n",
            "        Blue       0.88      0.93      0.91       153\n",
            "       Brown       0.81      0.82      0.82        68\n",
            "       Green       0.92      0.94      0.93       230\n",
            "        Grey       0.71      0.47      0.57        32\n",
            "      Orange       0.73      0.84      0.78        32\n",
            "        Pink       0.80      0.83      0.81        92\n",
            "      Purple       0.83      0.69      0.76        78\n",
            "         Red       0.81      0.68      0.74        37\n",
            "       White       0.50      0.50      0.50         2\n",
            "      Yellow       0.69      0.79      0.73        28\n",
            "\n",
            "    accuracy                           0.85       758\n",
            "   macro avg       0.78      0.77      0.77       758\n",
            "weighted avg       0.85      0.85      0.84       758\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Initialize the Gradient Boosting model with regularization parameters\n",
        "gb_model = GradientBoostingClassifier(\n",
        "    n_estimators=100,        # Number of boosting stages to be run\n",
        "    learning_rate=0.1,       # Shrinks the contribution of each tree\n",
        "    max_depth=3,             # Maximum depth of the individual trees\n",
        "    min_samples_split=2,     # Minimum number of samples required to split an internal node\n",
        "    min_samples_leaf=1,      # Minimum number of samples required at a leaf node\n",
        "    subsample=0.9,           # Fraction of samples used to fit each individual tree\n",
        "    max_features='sqrt',     # Number of features to consider when looking for the best split\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "gb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_val_pred_gb = gb_model.predict(X_val)\n",
        "print(f'Gradient Boosting Validation Accuracy: {accuracy_score(y_val, y_val_pred_gb)}')\n",
        "print(\"Gradient Boosting Validation Classification Report:\")\n",
        "print(classification_report(y_val, y_val_pred_gb, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztayDxifHEfH"
      },
      "source": [
        "### hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-I6-STCi_6qx"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid for Gradient Boosting with regularization\n",
        "param_grid_gb = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'max_features': ['sqrt', 'log2', None]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV for Gradient Boosting\n",
        "grid_search_gb = GridSearchCV(GradientBoostingClassifier(random_state=42), param_grid_gb, cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV on the training data\n",
        "grid_search_gb.fit(X_train, y_train)\n",
        "\n",
        "# Get the best model from GridSearchCV\n",
        "best_gb = grid_search_gb.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the validation set\n",
        "y_val_pred_gb = best_gb.predict(X_val)\n",
        "print(f'Gradient Boosting Validation Accuracy: {accuracy_score(y_val, y_val_pred_gb)}')\n",
        "print(\"Gradient Boosting Validation Classification Report:\")\n",
        "print(classification_report(y_val, y_val_pred_gb, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR0m01PnFc_q"
      },
      "source": [
        "### Final evaluation - Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gf97YhODEo1r"
      },
      "outputs": [],
      "source": [
        "# Final evaluation on test data\n",
        "y_test_pred_gb = best_gb.predict(X_test)\n",
        "print(f'Gradient Boosting Test Accuracy: {accuracy_score(y_test, y_test_pred_gb)}')\n",
        "print(\"Gradient Boosting Test Classification Report:\")\n",
        "print(classification_report(y_test, y_test_pred_gb, target_names=label_encoder.classes_))\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best parameters found:\")\n",
        "print(grid_search_gb.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WD9mq6lUQ6BB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}